{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Trabajo Práctico Final: Linear/Quadratic Discriminant Analysis (LDA/QDA)\n",
        "\n",
        "### Definición: Clasificador Bayesiano\n",
        "\n",
        "Sean $k$ poblaciones, $x \\in \\mathbb{R}^p$ puede pertenecer a cualquiera $g \\in \\mathcal{G}$ de ellas. Bajo un esquema bayesiano, se define entonces $\\pi_j \\doteq P(G = j)$ la probabilidad *a priori* de que $X$ pertenezca a la clase *j*, y se **asume conocida** la distribución condicional de cada observable dado su clase $f_j \\doteq f_{X|G=j}$.\n",
        "\n",
        "De esta manera dicha probabilidad *a posteriori* resulta\n",
        "$$\n",
        "P(G|_{X=x} = j) = \\frac{f_{X|G=j}(x) \\cdot p_G(j)}{f_X(x)} \\propto f_j(x) \\cdot \\pi_j\n",
        "$$\n",
        "\n",
        "La regla de decisión de Bayes es entonces\n",
        "$$\n",
        "H(x) \\doteq \\arg \\max_{g \\in \\mathcal{G}} \\{ P(G|_{X=x} = j) \\} = \\arg \\max_{g \\in \\mathcal{G}} \\{ f_j(x) \\cdot \\pi_j \\}\n",
        "$$\n",
        "\n",
        "es decir, se predice a $x$ como perteneciente a la población $j$ cuya probabilidad a posteriori es máxima.\n",
        "\n",
        "*Ojo, a no desesperar! $\\pi_j$ no es otra cosa que una constante prefijada, y $f_j$ es, en su esencia, un campo escalar de $x$ a simplemente evaluar.*\n",
        "\n",
        "### Distribución condicional\n",
        "\n",
        "Para los clasificadores de discriminante cuadrático y lineal (QDA/LDA) se asume que $X|_{G=j} \\sim \\mathcal{N}_p(\\mu_j, \\Sigma_j)$, es decir, se asume que cada población sigue una distribución normal.\n",
        "\n",
        "Por definición, se tiene entonces que para una clase $j$:\n",
        "$$\n",
        "f_j(x) = \\frac{1}{(2 \\pi)^\\frac{p}{2} \\cdot |\\Sigma_j|^\\frac{1}{2}} e^{- \\frac{1}{2}(x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j)}\n",
        "$$\n",
        "\n",
        "Aplicando logaritmo (que al ser una función estrictamente creciente no afecta el cálculo de máximos/mínimos), queda algo mucho más práctico de trabajar:\n",
        "\n",
        "$$\n",
        "\\log{f_j(x)} = -\\frac{1}{2}\\log |\\Sigma_j| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j) + C\n",
        "$$\n",
        "\n",
        "Observar que en este caso $C=-\\frac{p}{2} \\log(2\\pi)$, pero no se tiene en cuenta ya que al tener una constante aditiva en todas las clases, no afecta al cálculo del máximo.\n",
        "\n",
        "### LDA\n",
        "\n",
        "En el caso de LDA se hace una suposición extra, que es $X|_{G=j} \\sim \\mathcal{N}_p(\\mu_j, \\Sigma)$, es decir que las poblaciones no sólo siguen una distribución normal sino que son de igual matriz de covarianzas. Reemplazando arriba se obtiene entonces:\n",
        "\n",
        "$$\n",
        "\\log{f_j(x)} =  -\\frac{1}{2}\\log |\\Sigma| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j) + C\n",
        "$$\n",
        "\n",
        "Ahora, como $-\\frac{1}{2}\\log |\\Sigma|$ es común a todas las clases se puede incorporar a la constante aditiva y, distribuyendo y reagrupando términos sobre $(x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j)$ se obtiene finalmente:\n",
        "\n",
        "$$\n",
        "\\log{f_j(x)} =  \\mu_j^T \\Sigma^{-1} (x- \\frac{1}{2} \\mu_j) + C'\n",
        "$$\n",
        "\n",
        "### Entrenamiento/Ajuste\n",
        "\n",
        "Obsérvese que para ambos modelos, ajustarlos a los datos implica estimar los parámetros $(\\mu_j, \\Sigma_j) \\; \\forall j = 1, \\dots, k$ en el caso de QDA, y $(\\mu_j, \\Sigma)$ para LDA.\n",
        "\n",
        "Estos parámetros se estiman por máxima verosimilitud, de manera que los estimadores resultan:\n",
        "\n",
        "* $\\hat{\\mu}_j = \\bar{x}_j$ el promedio de los $x$ de la clase *j*\n",
        "* $\\hat{\\Sigma}_j = s^2_j$ la matriz de covarianzas estimada para cada clase *j*\n",
        "* $\\hat{\\pi}_j = f_{R_j} = \\frac{n_j}{n}$ la frecuencia relativa de la clase *j* en la muestra\n",
        "* $\\hat{\\Sigma} = \\frac{1}{n} \\sum_{j=1}^k n_j \\cdot s^2_j$ el promedio ponderado (por frecs. relativas) de las matrices de covarianzas de todas las clases. *Observar que se utiliza el estimador de MV y no el insesgado*\n",
        "\n",
        "Es importante notar que si bien todos los $\\mu, \\Sigma$ deben ser estimados, la distribución *a priori* puede no inferirse de los datos sino asumirse previamente, utilizándose como entrada del modelo.\n",
        "\n",
        "### Predicción\n",
        "\n",
        "Para estos modelos, al igual que para cualquier clasificador Bayesiano del tipo antes visto, la estimación de la clase es por método *plug-in* sobre la regla de decisión $H(x)$, es decir devolver la clase que maximiza $\\hat{f}_j(x) \\cdot \\hat{\\pi}_j$, o lo que es lo mismo $\\log\\hat{f}_j(x) + \\log\\hat{\\pi}_j$."
      ],
      "metadata": {
        "id": "bpJ7s_SIVu_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estructura del código"
      ],
      "metadata": {
        "id": "5TDWOgpJWKQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo"
      ],
      "metadata": {
        "id": "6yEV8WbiWl6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import det, inv"
      ],
      "metadata": {
        "id": "teF9O9JJmG7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassEncoder:\n",
        "  def fit(self, y):\n",
        "    self.names = np.unique(y)\n",
        "    self.name_to_class = {name:idx for idx, name in enumerate(self.names)}\n",
        "    self.fmt = y.dtype\n",
        "    # Q1: por que no hace falta definir un class_to_name para el mapeo inverso?\n",
        "\n",
        "  def _map_reshape(self, f, arr):\n",
        "    return np.array([f(elem) for elem in arr.flatten()]).reshape(arr.shape)\n",
        "    # Q2: por que hace falta un reshape?\n",
        "\n",
        "  def transform(self, y):\n",
        "    return self._map_reshape(lambda name: self.name_to_class[name], y)\n",
        "\n",
        "  def fit_transform(self, y):\n",
        "    self.fit(y)\n",
        "    return self.transform(y)\n",
        "\n",
        "  def detransform(self, y_hat):\n",
        "    return self._map_reshape(lambda idx: self.names[idx], y_hat)"
      ],
      "metadata": {
        "id": "sDBLvbTtlwzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0KYC8_uSOu4"
      },
      "outputs": [],
      "source": [
        "class BaseBayesianClassifier:\n",
        "  def __init__(self):\n",
        "    self.encoder = ClassEncoder()\n",
        "\n",
        "  def _estimate_a_priori(self, y):\n",
        "    a_priori = np.bincount(y.flatten().astype(int)) / y.size\n",
        "    # Q3: para que sirve bincount?\n",
        "    return np.log(a_priori)\n",
        "\n",
        "  def _fit_params(self, X, y):\n",
        "    # estimate all needed parameters for given model\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def _predict_log_conditional(self, x, class_idx):\n",
        "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
        "    # this should depend on the model used\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def fit(self, X, y, a_priori=None):\n",
        "    # first encode the classes\n",
        "    y = self.encoder.fit_transform(y)\n",
        "\n",
        "    # if it's needed, estimate a priori probabilities\n",
        "    self.log_a_priori = self._estimate_a_priori(y) if a_priori is None else np.log(a_priori)\n",
        "\n",
        "    # check that a_priori has the correct number of classes\n",
        "    assert len(self.log_a_priori) == len(self.encoder.names), \"A priori probabilities do not match number of classes\"\n",
        "\n",
        "    # now that everything else is in place, estimate all needed parameters for given model\n",
        "    self._fit_params(X, y)\n",
        "    # Q4: por que el _fit_params va al final? no se puede mover a, por ejemplo, antes de la priori?\n",
        "\n",
        "  def predict(self, X):\n",
        "    # this is actually an individual prediction encased in a for-loop\n",
        "    m_obs = X.shape[1]\n",
        "    y_hat = np.empty(m_obs, dtype=self.encoder.fmt)\n",
        "\n",
        "    for i in range(m_obs):\n",
        "      encoded_y_hat_i = self._predict_one(X[:,i].reshape(-1,1))\n",
        "      y_hat[i] = self.encoder.names[encoded_y_hat_i]\n",
        "\n",
        "    # return prediction as a row vector (matching y)\n",
        "    return y_hat.reshape(1,-1)\n",
        "\n",
        "  def _predict_one(self, x):\n",
        "    # calculate all log posteriori probabilities (actually, +C)\n",
        "    log_posteriori = [ log_a_priori_i + self._predict_log_conditional(x, idx) for idx, log_a_priori_i\n",
        "                  in enumerate(self.log_a_priori) ]\n",
        "\n",
        "    # return the class that has maximum a posteriori probability\n",
        "    return np.argmax(log_posteriori)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QDA(BaseBayesianClassifier):\n",
        "\n",
        "  def _fit_params(self, X, y):\n",
        "    # estimate each covariance matrix\n",
        "    self.inv_covs = [inv(np.cov(X[:,y.flatten()==idx], bias=True))\n",
        "                      for idx in range(len(self.log_a_priori))]\n",
        "    # Q5: por que hace falta el flatten y no se puede directamente X[:,y==idx]?\n",
        "    # Q6: por que se usa bias=True en vez del default bias=False?\n",
        "    self.means = [X[:,y.flatten()==idx].mean(axis=1, keepdims=True)\n",
        "                  for idx in range(len(self.log_a_priori))]\n",
        "    # Q7: que hace axis=1? por que no axis=0?\n",
        "\n",
        "  def _predict_log_conditional(self, x, class_idx):\n",
        "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
        "    # this should depend on the model used\n",
        "    inv_cov = self.inv_covs[class_idx]\n",
        "    unbiased_x =  x - self.means[class_idx]\n",
        "    return 0.5*np.log(det(inv_cov)) -0.5 * unbiased_x.T @ inv_cov @ unbiased_x"
      ],
      "metadata": {
        "id": "IRamFdiGDuSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TensorizedQDA(QDA):\n",
        "\n",
        "    def _fit_params(self, X, y):\n",
        "        # ask plain QDA to fit params\n",
        "        super()._fit_params(X,y)\n",
        "\n",
        "        # stack onto new dimension\n",
        "        self.tensor_inv_cov = np.stack(self.inv_covs)\n",
        "        self.tensor_means = np.stack(self.means)\n",
        "\n",
        "    def _predict_log_conditionals(self,x):\n",
        "        unbiased_x = x - self.tensor_means\n",
        "        inner_prod = unbiased_x.transpose(0,2,1) @ self.tensor_inv_cov @ unbiased_x\n",
        "\n",
        "        return 0.5*np.log(det(self.tensor_inv_cov)) - 0.5 * inner_prod.flatten()\n",
        "\n",
        "    def _predict_one(self, x):\n",
        "        # return the class that has maximum a posteriori probability\n",
        "        return np.argmax(self.log_a_priori + self._predict_log_conditionals(x))"
      ],
      "metadata": {
        "id": "fRtC9HEkO5Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Código para pruebas"
      ],
      "metadata": {
        "id": "KS_zoK-gWkRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seteamos los datos"
      ],
      "metadata": {
        "id": "nz19b6NJed2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hiperparámetros\n",
        "rng_seed = 6543"
      ],
      "metadata": {
        "id": "m05KrhUDINVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris, fetch_openml\n",
        "\n",
        "def get_iris_dataset():\n",
        "  data = load_iris()\n",
        "  X_full = data.data\n",
        "  y_full = np.array([data.target_names[y] for y in data.target.reshape(-1,1)])\n",
        "  return X_full, y_full\n",
        "\n",
        "def get_penguins():\n",
        "    # get data\n",
        "    df, tgt = fetch_openml(name=\"penguins\", return_X_y=True, as_frame=True)\n",
        "\n",
        "    # drop non-numeric columns\n",
        "    df.drop(columns=[\"island\",\"sex\"], inplace=True)\n",
        "\n",
        "    # drop rows with missing values\n",
        "    mask = df.isna().sum(axis=1) == 0\n",
        "    df = df[mask]\n",
        "    tgt = tgt[mask]\n",
        "\n",
        "    return df.values, tgt.to_numpy().reshape(-1,1)\n",
        "\n",
        "# showing for iris\n",
        "X_full, y_full = get_iris_dataset()\n",
        "\n",
        "print(f\"X: {X_full.shape}, Y:{y_full.shape}\")"
      ],
      "metadata": {
        "id": "2hkXcoldXOqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ce8d627-3433-4bdd-d370-85f6b703a7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: (150, 4), Y:(150, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# peek data matrix\n",
        "X_full[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAk-UQCjKecT",
        "outputId": "9566d67a-b78b-4809-bb94-8f605b065db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# peek target vector\n",
        "y_full[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdzMURX2KVdO",
        "outputId": "af5fc3ac-b391-4769-de47-44cea4f566c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['setosa'],\n",
              "       ['setosa'],\n",
              "       ['setosa'],\n",
              "       ['setosa'],\n",
              "       ['setosa']], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separamos el dataset en train y test para medir performance"
      ],
      "metadata": {
        "id": "Kl8UFh1OegbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing data, train - test validation\n",
        "# 70-30 split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_transpose(X, y, test_sz, random_state):\n",
        "    # split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.4, random_state=rng_seed)\n",
        "\n",
        "    # transpose so observations are column vectors\n",
        "    return X_train.T, y_train.T, X_test.T, y_test.T\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  return (y_true == y_pred).mean()\n",
        "\n",
        "train_x, train_y, test_x, test_y = split_transpose(X_full, y_full, 0.4, rng_seed)\n",
        "\n",
        "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKP_QmWCIECs",
        "outputId": "07798c6a-aa54-430e-d46d-becc2a4315ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 205) (1, 205) (4, 137) (1, 137)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos un QDA y medimos su accuracy"
      ],
      "metadata": {
        "id": "LwgXFPbJemb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qda = QDA()\n",
        "\n",
        "qda.fit(train_x, train_y)"
      ],
      "metadata": {
        "id": "dGIf2TA5SpoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = accuracy(train_y, qda.predict(train_x))\n",
        "test_acc = accuracy(test_y, qda.predict(test_x))\n",
        "print(f\"Train (apparent) error is {1-train_acc:.4f} while test error is {1-test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0Q30DyLWpTL",
        "outputId": "dbccae86-840c-412f-ed97-22cfac21238a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train (apparent) error is 0.0146 while test error is 0.0146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con el magic %%timeit podemos estimar el tiempo que tarda en correr una celda en base a varias ejecuciones. Por poner un ejemplo, acá vamos a estimar lo que tarda un ciclo completo de QDA y también su inferencia (predicción).\n",
        "\n",
        "Ojo! a veces [puede ser necesario ejecutarlo varias veces](https://stackoverflow.com/questions/10994405/python-timeit-results-cached-instead-of-calculated) para obtener resultados consistentes."
      ],
      "metadata": {
        "id": "-QcLtNNIevC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "\n",
        "qda.predict(test_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnZT-HN2fUuW",
        "outputId": "2618e7c1-7a77-4285-bafb-c2880ad167a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.9 ms ± 2.4 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "\n",
        "model = QDA()\n",
        "model.fit(train_x, train_y)\n",
        "model.predict(test_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjFbVSqfeHUX",
        "outputId": "0254a727-a1d5-4be3-b73a-2f55d2c84a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21.2 ms ± 7.36 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consigna\n",
        "\n",
        "## Implementación\n",
        "1. Entrenar un modelo QDA sobre el dataset *iris* utilizando las distribuciones *a priori* a continuación ¿Se observan diferencias?¿Por qué cree? _Pista: comparar con las distribuciones del dataset completo, **sin splitear**_.\n",
        "    1. Uniforme (cada clase tiene probabilidad 1/3)\n",
        "    2. Una clase con probabilidad 0.9, las demás 0.05 (probar las 3 combinaciones)\n",
        "2. Repetir el punto anterior para el dataset *penguin*.\n",
        "3. Implementar el modelo LDA, entrenarlo y testearlo contra los mismos sets que QDA ¿Se observan diferencias? ¿Podría decirse que alguno de los dos es notoriamente mejor que el otro?\n",
        "4. Utilizar otros 2 (dos) valores de *random seed* para obtener distintos splits de train y test, y repetir la comparación del punto anterior ¿Las conclusiones previas se mantienen?\n",
        "5. Estimar y comparar los tiempos de predicción de las clases `QDA` y `TensorizedQDA`. De haber diferencias ¿Cuáles pueden ser las causas?\n",
        "\n",
        "\n",
        "**Sugerencia:** puede resultar de utilidad para los puntos de comparación utilizar tablas del siguiente estilo:\n",
        "\n",
        "<center>\n",
        "\n",
        "Modelo | Dataset | Seed | Error (train) | Error (test)\n",
        ":---: | :---: | :---: | :---: | :---:\n",
        "QDA | Iris | 125 | 0.55 | 0.85\n",
        "LDA | Iris | 125 | 0.22 | 0.8\n",
        "\n",
        "</center>\n",
        "\n",
        "## Preguntas teóricas\n",
        "\n",
        "1. En LDA se menciona que la función a maximizar puede ser, mediante operaciones, convertida en:\n",
        "$$\n",
        "\\log{f_j(x)} =  \\mu_j^T \\Sigma^{-1} (x- \\frac{1}{2} \\mu_j) + C'\n",
        "$$\n",
        "Mostrar los pasos por los cuales se llega a dicha expresión.\n",
        "2. Explicar, utilizando las respectivas funciones a maximizar, por qué QDA y LDA son \"quadratic\" y \"linear\".\n",
        "3. La implementación de QDA estima la probabilidad condicional utilizando `0.5*np.log(det(inv_cov)) -0.5 * unbiased_x.T @ inv_cov @ unbiased_x` que no es *exactamente* lo descrito en el apartado teórico ¿Cuáles son las diferencias y por qué son expresiones equivalentes?\n",
        "\n",
        "El espíritu de esta componente práctica es la de establecer un mínimo de trabajo aceptable para su entrega; se invita al alumno a explorar otros aspectos que generen curiosidad, sin sentirse de ninguna manera limitado por la consigna.\n",
        "\n",
        "## Ejercicio teórico\n",
        "\n",
        "Sea una red neuronal de dos capas, la primera de 3 neuronas y la segunda de 1 con los parámetros inicializados con los siguientes valores:\n",
        "$$\n",
        "w^{(1)} =\n",
        "\\begin{pmatrix}\n",
        "0.1 & -0.5 \\\\\n",
        "-0.3 & -0.9 \\\\\n",
        "0.8 & 0.02\n",
        "\\end{pmatrix},\n",
        "b^{(1)} = \\begin{pmatrix}\n",
        "0.1 \\\\\n",
        "0.5 \\\\\n",
        "0.8\n",
        "\\end{pmatrix},\n",
        "w^{(2)} =\n",
        "\\begin{pmatrix}\n",
        "-0.4 & 0.2 & -0.5\n",
        "\\end{pmatrix},\n",
        "b^{(2)} = 0.7\n",
        "$$\n",
        "\n",
        "y donde cada capa calcula su salida vía\n",
        "\n",
        "$$\n",
        "y^{(i)} = \\sigma (w^{(i)} \\cdot x^{(i)}+b^{(i)})\n",
        "$$\n",
        "\n",
        "donde $\\sigma (z) = \\frac{1}{1+e^{-z}}$ es la función sigmoidea .\n",
        "\n",
        "\\\\\n",
        "Dada la observación $x=\\begin{pmatrix}\n",
        "1.8 \\\\\n",
        "-3.4\n",
        "\\end{pmatrix}$, $y=5$ y la función de costo $J(\\theta)=\\frac{1}{2}(\\hat{y}_\\theta-y)^2$, calcular las derivadas de J respecto de cada parámetro $w^{(1)}$, $w^{(2)}$, $b^{(1)}$, $b^{(2)}$.\n",
        "\n",
        "*Nota: Con una sigmoidea a la salida jamás va a poder estimar el 5 \"pedido\", pero eso no afecta al mecanismo de backpropagation!*\n",
        "\n",
        "## Preguntas en el código\n",
        "Previamente las preguntas \"técnicas\" en comentarios en el código eran parte del TP, y buscaban que el alumno logre entrar en el detalle de por qué cada linea de código es como es y en el orden en el que está. Ya no forman parte de la consigna, pero se aconseja al alumno intentar responderlas. Las respuestas a las mismas se encuentran en un archivo separado.\n",
        "\n",
        "## Opcional\n",
        "\n",
        "### QDA\n",
        "\n",
        "Debido a la forma cuadrática de QDA, no se puede predecir para *n* observaciones en una sola pasada (utilizar $X \\in \\mathbb{R}^{p \\times n}$ en vez de $x \\in \\mathbb{R}^p$) sin pasar por una matriz de *n x n* en donde se computan todas las interacciones entre observaciones. Se puede acceder al resultado recuperando sólo la diagonal de dicha matriz, pero resulta ineficiente en tiempo y (especialmente) en memoria. Aún así, es *posible* que el modelo funcione más rápido.\n",
        "\n",
        "1. Implementar el modelo `FasterQDA` (se recomienda heredarlo de TensorizedQDA) de manera de eliminar el ciclo for en el método predict.\n",
        "2. Comparar los tiempos de predicción de `FasterQDA` con `TensorizedQDA` y `QDA`\n",
        "3. Mostrar (puede ser con un print) dónde aparece la mencionada matriz de *n x n*, donde *n* es la cantidad de observaciones a predecir.\n",
        "4.Demostrar\n",
        "$$\n",
        "diag(A \\cdot B) = \\sum_{cols} A \\odot B^T = np.sum(A \\odot B^T, axis=1)\n",
        "$$ es decir, que se puede \"esquivar\" la matriz de *n x n* usando matrices de *n x p*.\n",
        "5.Utilizar la propiedad antes demostrada para reimplementar la predicción del modelo `FasterQDA` de forma eficiente. ¿Hay cambios en los tiempos de predicción?\n",
        "\n",
        "\n",
        "### LDA\n",
        "\n",
        "1. \"Tensorizar\" el modelo LDA y comparar sus tiempos de predicción con el modelo antes implementado. *Notar que, en modo tensorizado, se puede directamente precomputar $\\mu^T \\cdot \\Sigma^{-1} \\in \\mathbb{R}^{k \\times 1 \\times p}$ y guardar eso en vez de $\\Sigma^{-1}$.*\n",
        "2. LDA no sufre del problema antes descrito de QDA debido a que no computa productos internos, por lo que no tiene un verdadero costo extra en memoria predecir \"en batch\". Implementar el modelo `FasterLDA` y comparar sus tiempos de predicción con las versiones anteriores de LDA."
      ],
      "metadata": {
        "id": "1Yb1V7_yXRfO"
      }
    }
  ]
}